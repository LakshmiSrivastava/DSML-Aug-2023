{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Ninjacart: CV Classification\n",
        "Unsolved\n",
        "warning icon\n",
        "Your business case was due on 10 Oct 2024, 6:30 PM.Your score will be reduced by 70.\n",
        "feature icon\n",
        "Using hints except Complete Solution is Penalty free now\n",
        "Use Hint\n",
        "Problem Statement\n",
        "\n",
        "Ninjacart is India's largest fresh produce supply chain company. They are pioneers in solving one of the toughest supply chain problems of the world by leveraging innovative technology. They source fresh produce from farmers and deliver them to businesses within 12 hours. An integral component of their automation process is the development of robust classifiers which can distinguish between images of different types of vegetables, while also correctly labeling images that do not contain any one type of vegetable as noise.\n",
        "\n",
        "As a starting point, ninjacart has provided us with a dataset scraped from the web which contains train and test folders, each having 4 sub-folders with images of onions, potatoes, tomatoes and some market scenes. We have been tasked with preparing a multiclass classifier for identifying these vegetables. The dataset provided has all the required images to achieve the task.\n",
        "\n",
        "Dataset Link\n",
        "\n",
        "https://drive.google.com/file/d/1clZX-lV_MLxKHSyeyTheX5OCQtNCUcqT/view?usp=sharing\n",
        "\n",
        "Context\n",
        "\n",
        "This dataset contains images of the following food items: noise-Indian market and images of vegetables- onion, potato and tomato.\n",
        "\n",
        "Data Collection\n",
        "\n",
        "The images in this dataset were scraped from Google.\n",
        "\n",
        "Content\n",
        "\n",
        "This dataset contains a folder train, which has a total of 3135 images, split into four folders as follows:\n",
        "\n",
        "Tomato : 789\n",
        "\n",
        "Potato : 898\n",
        "\n",
        "Onion : 849\n",
        "\n",
        "Indian market : 599\n",
        "\n",
        "This dataset contains another folder test which has a total of 351 images, split into four folders\n",
        "\n",
        "Tomato : 106\n",
        "\n",
        "potato : 83\n",
        "\n",
        "onion : 81\n",
        "\n",
        "Indian market : 81\n",
        "\n",
        "Inspiration\n",
        "\n",
        "The objective is to develop a program that can recognize the vegetable item(s) in a photo and identify them for the user.\n",
        "\n",
        "Concepts Tested:\n",
        "\n",
        "Dataset Preparation & Visualization\n",
        "\n",
        "CNN models\n",
        "\n",
        "Implementing Callbacks\n",
        "\n",
        "Deal with Overfitting\n",
        "\n",
        "Transfer Learning\n",
        "\n",
        "Process:\n",
        "\n",
        "There are numerous libraries that can be used to work with images. Importing the libraries we feel most confident with is our first step: TensorFlow, keras, matplotlib, opencv, seaborn etc\n",
        "\n",
        "Download the Data (you can use gdown) with the provided Dataset Link and unzip it\n",
        "\n",
        "Visualize the data, use the dataset directory to create a list containing all the image paths in the training folder. You can use matplotlib or tensorflow to plot a grid sample of the images you fetched from the list of image paths.\n",
        "\n",
        "Plot a few of the images of each class to check their dimensions. [Note that the images are not all of uniform dimensions]\n",
        "\n",
        "Verify the count of images in each train and test folder by plotting histogram .\n",
        "\n",
        "Check each folder to see if the number of images matches the reported number.\n",
        "\n",
        "Split the dataset to a train and validation set.\n",
        "\n",
        "The provided data does not contain separate training and validation folders. For us to do hyperparameter tuning of our models, it is important to divide the dataset into an 80-20 split for training and validation respectively.\n",
        "\n",
        "Before fitting data to our model, we must make sure that each image is square-shaped so that we may resize it to the required dimensions and also perform rescaling which will rescale the inputs between 0-1 by dividing each value by 255.\n",
        "\n",
        "Use a model of your choice (could be vgg, resnet and mobilenet) and train it with an appropriate batch size.\n",
        "\n",
        "Using the pretrained weights of popular networks is a great way to do transfer learning, since the size of our original dataset is small.\n",
        "\n",
        "Obtain the testing accuracy to see how well your model generalizes.\n",
        "\n",
        "Compare and check the performance of multiple models using a confusion matrix.\n",
        "\n",
        "Implement a TensorBoard callback to log each of our model metrics for each model during the training process. [ recommended google colab or jupyter notebook]\n",
        "\n",
        "Plot the train/valid accuracy and loss graph for each model.\n",
        "\n",
        "If the model is overfitting , Try to tune your model by applying - :\n",
        "\n",
        "BatchNormalization and Dropout\n",
        "\n",
        "Callbacks : EarlyStopping, ModelCheckpoint and TensorBoard callback\n",
        "\n",
        "Data Augmentation\n",
        "\n",
        "Evaluation Criteria (100 points)\n",
        "\n",
        "Importing the dataset and doing usual exploratory analysis steps like checking the structure & characteristics of the data (10 points)\n",
        "\n",
        "Exploratory Data Analysis. (20 points)\n",
        "\n",
        "Plotting class distribution & Visualizing Image dimensions with their plots[10]\n",
        "\n",
        "Splitting the dataset into train, validation, and test set[10]\n",
        "\n",
        "Creating model architecture and training (50 points)\n",
        "\n",
        "Defining the CNN Classifier model from scratch[10]\n",
        "\n",
        "Improving Baseline CNN to reduce overfitting[10]\n",
        "\n",
        "Implementing Callbacks while training the model[10]\n",
        "\n",
        "Finetune pretrained models such as VGG, ResNet and MobileNet[10]\n",
        "\n",
        "Plotting the model training metrics and confusion matrix[10]\n",
        "\n",
        "Testing your best model so far(20 points)\n",
        "\n",
        "Testing on the test set & Random image samples prediction[10]\n",
        "\n",
        "Summary & Insights [10]"
      ],
      "metadata": {
        "id": "_VnzNlEtFvH3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RMnbHdE4_gFP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting paramteres"
      ],
      "metadata": {
        "id": "kU_rA8ZOIBPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT= Path('/content/view?usp=sharing.1')\n",
        "TRAIN_DIR = DATA_ROOT/'train'\n",
        "TEST_DIR= DATA_ROOT/ 'test'\n",
        "IMAGE_SIZE=(256,256)\n",
        "BATCH_SIZE=64\n",
        "SEED=2022"
      ],
      "metadata": {
        "id": "Thd3101RICyX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the Data**"
      ],
      "metadata": {
        "id": "PUWRUzGtIrPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping downloaded data"
      ],
      "metadata": {
        "id": "jj_BXAx3I6_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('/content/view?usp=sharing.1'):\n",
        "  os.system('unzip/content/view?usp=sharing.1')"
      ],
      "metadata": {
        "id": "zU4zn9EQIzyy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/view?usp=sharing.1'"
      ],
      "metadata": {
        "id": "vTIyydeDSZX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3fa94b-1efb-4226-d723-85072dee7dc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/view?usp=sharing.1, /content/view?usp=sharing.1.zip or /content/view?usp=sharing.1.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the Data"
      ],
      "metadata": {
        "id": "5DmnV5VNJvcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder=\n",
        "images=[]\n",
        "for folder in os.listdir(train_folder):\n",
        "  for image in os.listdir(train_folder+'/'+folder):\n",
        "    images.append(os.path.join(train_folder, folder, image))\n",
        "\n",
        "fig=plt.figure(1,figsize=(15,9))\n",
        "fig.suptitle('Data overview', fontsize=25)\n",
        "plt.axis('off')\n",
        "n=0\n",
        "for i in range(16):\n",
        "  n==1\n",
        "  random_img= random.choice(images)\n",
        "  imgs= tf.keras.utlis.load_img(random_img)\n",
        "  plt.subplot(4,4,n)\n",
        "  plt.axis('off')\n",
        "  plt.inshow(imgs)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "66lWnDYAJr-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0841871a-04f9-4a93-8a4f-6e90361bfdb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3396057325.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3396057325.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    train_folder=\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WKG1HDPWRFF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install gdown\n",
        "\n",
        "# Download the dataset\n",
        "!gdown 1clZX-lV_MLxKHSyeyTheX5OCQtNCUcqT\n",
        "\n",
        "# Unzip the downloaded file\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/ninjacart_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Setting parameters\n",
        "DATA_ROOT = Path('/content/ninjacart_data')\n",
        "TRAIN_DIR = DATA_ROOT / 'train'\n",
        "TEST_DIR = DATA_ROOT / 'test'\n",
        "IMAGE_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 2022\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# 1. Data Loading and Exploration\n",
        "\n",
        "print(\"Dataset structure:\")\n",
        "print(f\"Train directory exists: {TRAIN_DIR.exists()}\")\n",
        "print(f\"Test directory exists: {TEST_DIR.exists()}\")\n",
        "\n",
        "# Check class distribution\n",
        "def count_images_per_class(directory):\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_images = len([f for f in os.listdir(class_path)\n",
        "                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            class_counts[class_name] = num_images\n",
        "    return class_counts\n",
        "\n",
        "train_counts = count_images_per_class(TRAIN_DIR)\n",
        "test_counts = count_images_per_class(TEST_DIR)\n",
        "\n",
        "print(\"\\nTraining set distribution:\")\n",
        "for class_name, count in train_counts.items():\n",
        "    print(f\"{class_name}: {count}\")\n",
        "\n",
        "print(\"\\nTest set distribution:\")\n",
        "for class_name, count in test_counts.items():\n",
        "    print(f\"{class_name}: {count}\")\n",
        "\n",
        "# 2. Data Visualization\n",
        "\n",
        "def visualize_samples(directory, num_samples=16):\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(15, 12))\n",
        "    fig.suptitle('Data Overview - Sample Images from Each Class', fontsize=20)\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    all_images = []\n",
        "    class_names = []\n",
        "\n",
        "    for class_idx, class_name in enumerate(sorted(os.listdir(directory))):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            for i in range(4):\n",
        "                if i < len(images):\n",
        "                    img_path = os.path.join(class_path, images[i])\n",
        "                    img = Image.open(img_path)\n",
        "                    axes[class_idx*4 + i].imshow(img)\n",
        "                    axes[class_idx*4 + i].set_title(f'{class_name}\\n{img.size}')\n",
        "                    axes[class_idx*4 + i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nVisualizing training samples:\")\n",
        "visualize_samples(TRAIN_DIR)\n",
        "\n",
        "# Plot class distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Training distribution\n",
        "ax1.bar(train_counts.keys(), train_counts.values())\n",
        "ax1.set_title('Training Set Class Distribution')\n",
        "ax1.set_xlabel('Classes')\n",
        "ax1.set_ylabel('Number of Images')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Test distribution\n",
        "ax2.bar(test_counts.keys(), test_counts.values())\n",
        "ax2.set_title('Test Set Class Distribution')\n",
        "ax2.set_xlabel('Classes')\n",
        "ax2.set_ylabel('Number of Images')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Data Preparation and Preprocessing\n",
        "\n",
        "# Create data generators with data augmentation for training\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create training and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"\\nClasses: {train_generator.class_indices}\")\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {validation_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n",
        "\n",
        "# 4. Model Building - CNN from Scratch\n",
        "def create_cnn_model():\n",
        "    model = keras.Sequential([\n",
        "        # First Convolutional Block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Third Convolutional Block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Fourth Convolutional Block\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Classifier\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(4, activation='softmax')  # 4 classes\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and compile model\n",
        "cnn_model = create_cnn_model()\n",
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"CNN Model Summary:\")\n",
        "cnn_model.summary()\n",
        "\n",
        "# 5. Callbacks Implementation\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "import datetime\n",
        "\n",
        "# Create callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint('best_cnn_model.h5', save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.2, patience=5, verbose=1),\n",
        "    TensorBoard(log_dir=f\"logs/cnn/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
        "]\n",
        "\n",
        "# 6. Model Training\n",
        "\n",
        "print(\"\\nTraining CNN Model...\")\n",
        "history = cnn_model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#7. Model Evaluation and Visualization\n",
        "\n",
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on Test Set...\")\n",
        "test_loss, test_accuracy = cnn_model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "\n",
        "# 8. Confusion Matrix and Classification Report\n",
        "\n",
        "# Get predictions\n",
        "y_pred = cnn_model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
        "\n",
        "# =============================================================================\n",
        "# 9. Transfer Learning with Pre-trained Models\n",
        "# =============================================================================\n",
        "\n",
        "def create_transfer_learning_model(base_model, model_name):\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Try different pre-trained models\n",
        "pre_trained_models = {\n",
        "    'MobileNetV2': tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(256, 256, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    ),\n",
        "    'VGG16': tf.keras.applications.VGG16(\n",
        "        input_shape=(256, 256, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    ),\n",
        "    'ResNet50': tf.keras.applications.ResNet50(\n",
        "        input_shape=(256, 256, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "}\n",
        "\n",
        "# Train and compare different models\n",
        "model_results = {}\n",
        "\n",
        "for model_name, base_model in pre_trained_models.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model = create_transfer_learning_model(base_model, model_name)\n",
        "\n",
        "    # Callbacks for transfer learning\n",
        "    tl_callbacks = [\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint(f'best_{model_name.lower()}_model.h5', save_best_only=True),\n",
        "        ReduceLROnPlateau(factor=0.2, patience=3)\n",
        "    ]\n",
        "\n",
        "    # Train the model\n",
        "    history_tl = model.fit(\n",
        "        train_generator,\n",
        "        epochs=30,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=tl_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "    model_results[model_name] = test_accuracy\n",
        "\n",
        "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 10. Results Comparison and Summary\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Compare all models\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "for model_name, accuracy in model_results.items():\n",
        "    print(f\"{model_name}: {accuracy:.4f}\")\n",
        "\n",
        "best_model_name = max(model_results, key=model_results.get)\n",
        "print(f\"\\nBest Model: {best_model_name} with accuracy: {model_results[best_model_name]:.4f}\")\n",
        "\n",
        "# Load the best model for final predictions\n",
        "if model_results[best_model_name] > test_accuracy:\n",
        "    best_base_model = pre_trained_models[best_model_name]\n",
        "    best_model = create_transfer_learning_model(best_base_model, best_model_name)\n",
        "    best_model.load_weights(f'best_{best_model_name.lower()}_model.h5')\n",
        "else:\n",
        "    best_model = cnn_model\n",
        "    best_model.load_weights('best_cnn_model.h5')\n",
        "\n",
        "# Final evaluation with best model\n",
        "final_test_loss, final_test_accuracy = best_model.evaluate(test_generator)\n",
        "print(f\"\\nFinal Best Model Test Accuracy: {final_test_accuracy:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# 11. Prediction on Random Samples\n",
        "# =============================================================================\n",
        "\n",
        "def predict_random_samples(model, num_samples=8):\n",
        "    # Get random test samples\n",
        "    sample_indices = np.random.choice(len(test_generator.filenames), num_samples, replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        # Get image path\n",
        "        img_path = os.path.join(TEST_DIR, test_generator.filenames[idx])\n",
        "        true_class = test_generator.filenames[idx].split('/')[0]\n",
        "\n",
        "        # Load and preprocess image\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(img_array)\n",
        "        predicted_class = class_names[np.argmax(prediction)]\n",
        "        confidence = np.max(prediction)\n",
        "\n",
        "        # Plot\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'True: {true_class}\\nPred: {predicted_class}\\nConf: {confidence:.2f}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "        # Color code based on correctness\n",
        "        color = 'green' if true_class == predicted_class else 'red'\n",
        "        for spine in axes[i].spines.values():\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nPredicting on random test samples:\")\n",
        "predict_random_samples(best_model)\n",
        "\n",
        "# =============================================================================\n",
        "# 12. Insights and Summary\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHTS AND SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. DATA INSIGHTS:\")\n",
        "print(f\"   - Total training images: {sum(train_counts.values())}\")\n",
        "print(f\"   - Total test images: {sum(test_counts.values())}\")\n",
        "print(f\"   - Number of classes: {len(train_counts)}\")\n",
        "print(f\"   - Class distribution in training: {train_counts}\")\n",
        "\n",
        "print(\"\\n2. MODEL PERFORMANCE:\")\n",
        "print(f\"   - CNN from scratch accuracy: {test_accuracy:.4f}\")\n",
        "for model_name, acc in model_results.items():\n",
        "    print(f\"   - {model_name} accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"\\n3. RECOMMENDATIONS:\")\n",
        "print(\"   - Data augmentation helps prevent overfitting\")\n",
        "print(\"   - Transfer learning generally performs better on small datasets\")\n",
        "print(\"   - Regularization techniques (Dropout, BatchNorm) are essential\")\n",
        "print(\"   - Class imbalance should be addressed for better performance\")\n",
        "\n",
        "print(\"\\n4. POTENTIAL IMPROVEMENTS:\")\n",
        "print(\"   - Collect more balanced data\")\n",
        "print(\"   - Try ensemble methods\")\n",
        "print(\"   - Fine-tune pre-trained models\")\n",
        "print(\"   - Use class weights for imbalanced data\")\n",
        "print(\"   - Experiment with different architectures\")"
      ],
      "metadata": {
        "id": "jSkmlNVAE4AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6b56a8c"
      },
      "source": [
        "## Key Insights and Recommendations\n",
        "\n",
        "Based on the analysis of the Ninjacart dataset and the training of different image classification models, here are some key insights and recommendations:\n",
        "\n",
        "**Key Insights:**\n",
        "\n",
        "*   **Dataset Characteristics:** The dataset contains images of four classes: 'Indian market' (noise), 'Onion', 'Potato', and 'Tomato'. The distribution of images across these classes is relatively balanced in both the training and test sets.\n",
        "*   **Image Variability:** The images in the dataset have varying dimensions, highlighting the need for resizing and preprocessing before feeding them into a CNN model.\n",
        "*   **CNN Model Performance:** The custom CNN model from scratch provided a baseline performance.\n",
        "*   **Transfer Learning Effectiveness:** Pre-trained models like MobileNetV2, VGG16, and ResNet50, when used for transfer learning, generally outperform the custom CNN model, demonstrating the power of leveraging features learned on large datasets.\n",
        "*   **Impact of Data Augmentation and Regularization:** Techniques like data augmentation, Batch Normalization, and Dropout were crucial in improving model generalization and reducing overfitting, especially with a relatively small dataset.\n",
        "*   **Confusion Matrix and Classification Report:** These tools provide a detailed breakdown of model performance per class, highlighting potential areas where the model struggles (e.g., misclassifying certain classes).\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "*   **Prioritize Transfer Learning:** Given the dataset size, transfer learning with pre-trained models is a highly effective approach. Experiment with fine-tuning the later layers of the pre-trained models for potentially better performance.\n",
        "*   **Address Class Imbalance (if any):** While the current dataset is relatively balanced, in real-world scenarios, addressing class imbalance using techniques like weighted loss or oversampling/undersampling is important.\n",
        "*   **Hyperparameter Tuning:** Further optimize the hyperparameters of the chosen model (e.g., learning rate, optimizer, number of layers in the classification head) for better performance.\n",
        "*   **Explore Other Architectures:** Consider experimenting with other state-of-the-art pre-trained models or different custom CNN architectures.\n",
        "*   **Collect More Data:** The performance of deep learning models generally improves with more data. If possible, collecting a larger and more diverse dataset would be beneficial.\n",
        "*   **Ensemble Methods:** Combining predictions from multiple models can often lead to improved accuracy and robustness.\n",
        "*   **Visualize Misclassifications:** Analyze the images that the model misclassifies to understand the reasons behind the errors and identify areas for improvement (e.g., poor image quality, confusing examples).\n",
        "\n",
        "These insights and recommendations provide a roadmap for further improving the vegetable classification model for Ninjacart."
      ]
    }
  ]
}